{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c8f402-cc0c-436f-8898-06ecc316f51a",
   "metadata": {},
   "source": [
    "## **MetaBioPros 1.0**\n",
    "\n",
    "#### This notebook integrates the metagenomic bioprospecting analysis  1.0.  \n",
    "#### The analysis included are:  \n",
    "#### 0. Set env\n",
    "#### 1. Identification of BGCs\n",
    "#### 2. Taxonnomic annotation of BGCs\n",
    "#### 3. BGC sequences mapping onto referecne Gene Cluster Families (GCFs)\n",
    "#### 4. BGCs diversity estimates, functional prediction, and novelty assessment\n",
    "\n",
    "#### **Dependencies to run this notebook (outside the tools we provide):**  \n",
    "#### [aws cli](https://aws.amazon.com/cli/)  \n",
    "#### [bash and R kernels](https://evodify.com/python-r-bash-jupyter-notebook/)  \n",
    "#### [Docker](https://www.docker.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc2398-db3e-4ec2-9b48-848bc6c832b8",
   "metadata": {},
   "source": [
    "**0. Set env**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1357053d-48e1-445e-a0de-e42f0da41828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WORKDIR=workdir\n",
      "env: REPO=/home/epereira/workspace/dev/new_atlantis/repos/bioprospecting\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%set_env WORKDIR=workdir\n",
    "%set_env REPO=/home/epereira/workspace/dev/new_atlantis/repos/bioprospecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc7003a2-c4e3-489f-b171-d1920dbd38df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ${WORKDIR}/data/sola\n",
    "mkdir -p ${WORKDIR}/outputs/antismash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9241-fdfe-4d2d-b5ee-c5537507ad63",
   "metadata": {
    "tags": []
   },
   "source": [
    " **1. Identification of BGCs**\n",
    " \n",
    "We will be using the [SOLA metagenomic dataset](https://www.nature.com/articles/s41396-018-0158-1), already assembled with [VEBA](https://github.com/jolespin/veba).\n",
    "Letâ€™s first get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b0f1c-7cb4-47b0-815d-fb8ac3723414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# aws s3 cp s3://newatlantis-case-studies/SOLA-samples/ ${WORKDIR}/data/sola --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a468a9-ac35-4c38-967b-6e68bb31bef8",
   "metadata": {},
   "source": [
    "This dataset contains the assembled scaffolds (\\*.fasta) and the mapping files (\\*.bam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e84e70-3389-49d3-9fad-9049dcb70132",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workdir/data/sola/ERR2604071/output:\n",
      "featurecounts.tsv.gz\n",
      "mapped.sorted.bam\n",
      "mapped.sorted.bam.bai\n",
      "scaffolds.fasta\n",
      "scaffolds.fasta.1.bt2\n",
      "scaffolds.fasta.2.bt2\n",
      "scaffolds.fasta.3.bt2\n",
      "scaffolds.fasta.4.bt2\n",
      "scaffolds.fasta.rev.1.bt2\n",
      "scaffolds.fasta.rev.2.bt2\n",
      "scaffolds.fasta.saf\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ${WORKDIR}/data/sola/ERR*/output | head -12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcece54-3f7f-48fc-8bea-cd9d784a00b0",
   "metadata": {},
   "source": [
    "Now that we have the data, let's run [antisMASH](https://github.com/antismash/antismash) to identify the BGC sequences.  \n",
    "For this we will be using our wrap script [run_antismash](https://github.com/pereiramemo/bioprospecting/blob/main/run_scripts/run_antismash.sh), which runs a containerized version 6.0.0 of antiSMASH.  \n",
    "Note that there is version 7.0.0 available, but for compatibility purposes in downstream analysis, we'll use this version for now.\n",
    "Since we are using a wrap script to run a containerized version of antiSMASH, we have to use the fist two positional parameters as the input and output folders, respectively.  \n",
    "To see the help we run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c291c2-f727-4198-9941-3cf538950c62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########### antiSMASH 6.0.0 #############\n",
      "\n",
      "usage: antismash [--taxon {bacteria,fungi}] [--output-dir OUTPUT_DIR]\n",
      "                 [--output-basename OUTPUT_BASENAME] [--reuse-results PATH]\n",
      "                 [--limit LIMIT] [--minlength MINLENGTH] [--start START]\n",
      "                 [--end END] [--databases PATH] [--write-config-file PATH]\n",
      "                 [--without-fimo]\n",
      "                 [--executable-paths EXECUTABLE=PATH,EXECUTABLE2=PATH2,...]\n",
      "                 [--allow-long-headers] [-v] [-d] [--logfile PATH]\n",
      "                 [--list-plugins] [--check-prereqs]\n",
      "                 [--limit-to-record RECORD_ID] [-V] [--profiling]\n",
      "                 [--skip-sanitisation] [--skip-zip-file] [--minimal]\n",
      "                 [--enable-genefunctions] [--enable-tta]\n",
      "                 [--enable-lanthipeptides] [--enable-thiopeptides]\n",
      "                 [--enable-nrps-pks] [--enable-sactipeptides]\n",
      "                 [--enable-lassopeptides] [--enable-t2pks] [--enable-html]\n",
      "                 [--genefinding-tool {glimmerhmm,prodigal,prodigal-m,none,error}]\n",
      "                 [--genefinding-gff3 GFF3_FILE]\n",
      "                 [--hmmdetection-strictness {strict,relaxed,loose}]\n",
      "                 [--fullhmmer]\n",
      "                 [--fullhmmer-pfamdb-version FULLHMMER_PFAMDB_VERSION]\n",
      "                 [--cassis] [--clusterhmmer]\n",
      "                 [--clusterhmmer-pfamdb-version CLUSTERHMMER_PFAMDB_VERSION]\n",
      "                 [--sideload JSON] [--sideload-simple ACCESSION:START-END]\n",
      "                 [--tigrfam] [--smcog-trees] [--tta-threshold TTA_THRESHOLD]\n",
      "                 [--cb-general] [--cb-subclusters] [--cb-knownclusters]\n",
      "                 [--cb-nclusters count] [--cb-min-homology-scale LIMIT]\n",
      "                 [--asf] [--pfam2go] [--rre] [--rre-cutoff RRE_CUTOFF]\n",
      "                 [--rre-minlength RRE_MIN_LENGTH] [--cc-mibig]\n",
      "                 [--cc-custom-dbs FILE1,FILE2,...] [--html-title HTML_TITLE]\n",
      "                 [--html-description HTML_DESCRIPTION] [--html-start-compact]\n",
      "                 [-h] [--help-showall] [-c CPUS]\n",
      "                 [SEQUENCE [SEQUENCE ...]]\n",
      "\n",
      "\n",
      "arguments:\n",
      "  SEQUENCE  GenBank/EMBL/FASTA file(s) containing DNA.\n",
      "\n",
      "--------\n",
      "Options\n",
      "--------\n",
      "-h, --help              Show this help text.\n",
      "--help-showall          Show full lists of arguments on this help text.\n",
      "-c CPUS, --cpus CPUS    How many CPUs to use in parallel. (default: 48)\n",
      "\n",
      "Basic analysis options:\n",
      "\n",
      "  --taxon {bacteria,fungi}\n",
      "                        Taxonomic classification of input sequence. (default:\n",
      "                        bacteria)\n",
      "\n",
      "Additional analysis:\n",
      "\n",
      "  --fullhmmer           Run a whole-genome HMMer analysis.\n",
      "  --cassis              Motif based prediction of SM gene cluster regions.\n",
      "  --clusterhmmer        Run a cluster-limited HMMer analysis.\n",
      "  --tigrfam             Annotate clusters using TIGRFam profiles.\n",
      "  --smcog-trees         Generate phylogenetic trees of sec. met. cluster\n",
      "                        orthologous groups.\n",
      "  --tta-threshold TTA_THRESHOLD\n",
      "                        Lowest GC content to annotate TTA codons at (default:\n",
      "                        0.65).\n",
      "  --cb-general          Compare identified clusters against a database of\n",
      "                        antiSMASH-predicted clusters.\n",
      "  --cb-subclusters      Compare identified clusters against known subclusters\n",
      "                        responsible for synthesising precursors.\n",
      "  --cb-knownclusters    Compare identified clusters against known gene\n",
      "                        clusters from the MIBiG database.\n",
      "  --asf                 Run active site finder analysis.\n",
      "  --pfam2go             Run Pfam to Gene Ontology mapping module.\n",
      "  --rre                 Run RREFinder precision mode on all RiPP gene\n",
      "                        clusters.\n",
      "  --cc-mibig            Run a comparison against the MIBiG dataset\n",
      "\n",
      "Output options:\n",
      "\n",
      "  --output-dir OUTPUT_DIR\n",
      "                        Directory to write results to.\n",
      "  --output-basename OUTPUT_BASENAME\n",
      "                        Base filename to use for output files within the\n",
      "                        output directory.\n",
      "  --html-title HTML_TITLE\n",
      "                        Custom title for the HTML output page (default is\n",
      "                        input filename).\n",
      "  --html-description HTML_DESCRIPTION\n",
      "                        Custom description to add to the output.\n",
      "  --html-start-compact  Use compact view by default for overview page.\n",
      "\n",
      "Advanced options:\n",
      "\n",
      "  --reuse-results PATH  Use the previous results from the specified json\n",
      "                        datafile\n",
      "  --limit LIMIT         Only process the first <limit> records (default: -1).\n",
      "                        -1 to disable\n",
      "  --minlength MINLENGTH\n",
      "                        Only process sequences larger than <minlength>\n",
      "                        (default: 1000).\n",
      "  --start START         Start analysis at nucleotide specified.\n",
      "  --end END             End analysis at nucleotide specified\n",
      "  --databases PATH      Root directory of the databases (default:\n",
      "                        /usr/local/lib/python3.7/dist-\n",
      "                        packages/antismash/databases).\n",
      "  --write-config-file PATH\n",
      "                        Write a config file to the supplied path\n",
      "  --without-fimo        Run without FIMO (lowers accuracy of RiPP precursor\n",
      "                        predictions)\n",
      "  --executable-paths EXECUTABLE=PATH,EXECUTABLE2=PATH2,...\n",
      "                        A comma separated list of executable name->path pairs\n",
      "                        to override any on the system path.E.g.\n",
      "                        diamond=/alternate/path/to/diamond,hmmpfam2=hmm2pfam\n",
      "  --allow-long-headers  Prevents long headers from being renamed\n",
      "  --hmmdetection-strictness {strict,relaxed,loose}\n",
      "                        Defines which level of strictness to use for HMM-based\n",
      "                        cluster detection, (default: relaxed).\n",
      "  --sideload JSON       Sideload annotations from the JSON file in the given\n",
      "                        paths. Multiple files can be provided, separated by a\n",
      "                        comma.\n",
      "  --sideload-simple ACCESSION:START-END\n",
      "                        Sideload a single subregion in record ACCESSION from\n",
      "                        START to END. Positions are expected to be 0-indexed,\n",
      "                        with START inclusive and END exclusive.\n",
      "\n",
      "Debugging & Logging options:\n",
      "\n",
      "  -v, --verbose         Print verbose status information to stderr.\n",
      "  -d, --debug           Print debugging information to stderr.\n",
      "  --logfile PATH        Also write logging output to a file.\n",
      "  --list-plugins        List all available sec. met. detection modules.\n",
      "  --check-prereqs       Just check if all prerequisites are met.\n",
      "  --limit-to-record RECORD_ID\n",
      "                        Limit analysis to the record with ID record_id\n",
      "  -V, --version         Display the version number and exit.\n",
      "  --profiling           Generate a profiling report, disables multiprocess\n",
      "                        python.\n",
      "  --skip-sanitisation   Skip input record sanitisation. Use with care.\n",
      "  --skip-zip-file       Do not create a zip of the output\n",
      "\n",
      "Debugging options for cluster-specific analyses:\n",
      "\n",
      "  --minimal             Only run core detection modules, no analysis modules\n",
      "                        unless explicitly enabled\n",
      "  --enable-genefunctions\n",
      "                        Enable Gene function annotations (default: enabled,\n",
      "                        unless --minimal is specified)\n",
      "  --enable-tta          Enable TTA detection (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-lanthipeptides\n",
      "                        Enable Lanthipeptides (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-thiopeptides\n",
      "                        Enable Thiopeptides (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-nrps-pks     Enable NRPS/PKS analysis (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-sactipeptides\n",
      "                        Enable sactipeptide detection (default: enabled,\n",
      "                        unless --minimal is specified)\n",
      "  --enable-lassopeptides\n",
      "                        Enable lassopeptide precursor prediction (default:\n",
      "                        enabled, unless --minimal is specified)\n",
      "  --enable-t2pks        Enable type II PKS analysis (default: enabled, unless\n",
      "                        --minimal is specified)\n",
      "  --enable-html         Enable HTML output (default: enabled, unless --minimal\n",
      "                        is specified)\n",
      "\n",
      "Gene finding options (ignored when ORFs are annotated):\n",
      "\n",
      "  --genefinding-tool {glimmerhmm,prodigal,prodigal-m,none,error}\n",
      "                        Specify algorithm used for gene finding: GlimmerHMM,\n",
      "                        Prodigal, Prodigal Metagenomic/Anonymous mode, or\n",
      "                        none. The 'error' option will raise an error if\n",
      "                        genefinding is attempted. The 'none' option will not\n",
      "                        run genefinding. (default: error).\n",
      "  --genefinding-gff3 GFF3_FILE\n",
      "                        Specify GFF3 file to extract features from.\n",
      "\n",
      "Full HMMer options:\n",
      "\n",
      "  --fullhmmer-pfamdb-version FULLHMMER_PFAMDB_VERSION\n",
      "                        PFAM database version number (e.g. 27.0) (default:\n",
      "                        latest).\n",
      "\n",
      "Cluster HMMer options:\n",
      "\n",
      "  --clusterhmmer-pfamdb-version CLUSTERHMMER_PFAMDB_VERSION\n",
      "                        PFAM database version number (e.g. 27.0) (default:\n",
      "                        latest).\n",
      "\n",
      "TIGRFam options:\n",
      "\n",
      "NRPS/PKS options:\n",
      "\n",
      "ClusterBlast options:\n",
      "\n",
      "  --cb-nclusters count  Number of clusters from ClusterBlast to display,\n",
      "                        cannot be greater than 50. (default: 10)\n",
      "  --cb-min-homology-scale LIMIT\n",
      "                        A minimum scaling factor for the query BGC in\n",
      "                        ClusterBlast results. Valid range: 0.0 - 1.0. Warning:\n",
      "                        some homologous genes may no longer be visible!\n",
      "                        (default: 0.0)\n",
      "\n",
      "RREfinder options:\n",
      "\n",
      "  --rre-cutoff RRE_CUTOFF\n",
      "                        Bitscore cutoff for RRE pHMM detection (default:\n",
      "                        25.0).\n",
      "  --rre-minlength RRE_MIN_LENGTH\n",
      "                        Minimum amino acid length of RRE domains (default:\n",
      "                        50).\n",
      "\n",
      "ClusterCompare options:\n",
      "\n",
      "  --cc-custom-dbs FILE1,FILE2,...\n",
      "                        A comma separated list of database config files to run\n",
      "                        with\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\"${REPO}\"/run_scripts/run_antismash.sh . . --help-showall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d3bfdb-7eb1-40b4-920e-1be67935214b",
   "metadata": {},
   "source": [
    "Let's run antiSMASH on the SOLA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eab970-dfaa-4d2f-a483-0b62306e8a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR2604071\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "SCAFOLDS=$(ls ${WORKDIR}/data/sola/ERR*/output/scaffolds.fasta | head -3)\n",
    "for SCAFOLD in ${SCAFOLDS}; do\n",
    "\n",
    "  SAMPLE_NAME=$(echo \"${SCAFOLD}\" | sed \"s/.*\\(ERR[0-9]\\+\\)\\/output.*/\\1/\")\n",
    "  OUTPUT_DIR=\"${WORKDIR}/outputs/antismash/${SAMPLE_NAME}\"\n",
    "  echo \"${SAMPLE_NAME}\"\n",
    "    \n",
    "  \"${REPO}\"/run_scripts/run_antismash.sh \"${SCAFOLD}\" \"${OUTPUT_DIR}\" \\\n",
    "  --cpus 40 \\\n",
    "  --genefinding-tool prodigal-m \\\n",
    "  --taxon bacteria \\\n",
    "  --allow-long-headers \\\n",
    "  --minlength 5000\n",
    "\n",
    "done    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ff3ab-7de8-403a-a6ff-f7f193dcdf29",
   "metadata": {},
   "source": [
    "The annoated BGC sequences can be found in `${WORKDIR}/outputs/antismash/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f46a84-8b51-4879-94da-c50e657f9fa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR2604071\n",
      "ERR2604073\n",
      "ERR2604074\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ${WORKDIR}/outputs/antismash/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42888a2-1139-4204-aab5-5cbd4621af5c",
   "metadata": {},
   "source": [
    "Let's orgnize this data to run [BiG-SLICE](https://github.com/medema-group/bigslice): create the [dataset.tsv and taxonomy files](https://github.com/medema-group/bigslice/wiki/Input-folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33e2fc96-927e-4f41-aa35-82f57bd1be81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls -d \"${WORKDIR}/outputs/antismash/\"ERR* | \\\n",
    "while read LINE; do\n",
    "\n",
    "  DATASET=$(basename $(ls -d ${LINE}))\n",
    "  PATH2DATASET=$(basename $(dirname ${LINE}))\"/\"\n",
    "  echo -e \"${DATASET}\\t./\\ttaxonomy/${DATASET}_taxonomy.tsv\\tdataset_${DATASET}\"\n",
    "\n",
    "done > \"${WORKDIR}/outputs/antismash/datasets.tsv\"\n",
    "\n",
    "# mkdir \"${WORKDIR}/outputs/antismash/taxonomy\"\n",
    "\n",
    "cut -f3 \"${WORKDIR}/outputs/antismash/datasets.tsv\" | \\\n",
    "while read LINE; do\n",
    "  DATASET=$(basename \"${LINE}\" _taxonomy.tsv)\n",
    "  echo -e \"${DATASET}/\\tBacteria\" > \"${WORKDIR}/outputs/antismash/${LINE}\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b921001-f54f-4d55-8735-89b838d9eebe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Download the [BiG-FAM database](https://bigfam.bioinformatics.nl/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7f84a1e-d112-46fc-8feb-63124f039bc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-09-04 22:21:03--  http://bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip\n",
      "Resolving bioinformatics.nl (bioinformatics.nl)... 137.224.16.5\n",
      "Connecting to bioinformatics.nl (bioinformatics.nl)|137.224.16.5|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip [following]\n",
      "--2023-09-04 22:21:04--  https://www.bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip\n",
      "Resolving www.bioinformatics.nl (www.bioinformatics.nl)... 137.224.16.5\n",
      "Connecting to www.bioinformatics.nl (www.bioinformatics.nl)|137.224.16.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18075963830 (17G) [application/zip]\n",
      "Saving to: â€˜workdir/data/full_run_result.zipâ€™\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  137K 35h53m\n",
      "    50K .......... .......... .......... .......... ..........  0%  274K 26h54m\n",
      "   100K .......... .......... .......... .......... ..........  0% 12.7M 18h3m\n",
      "   150K .......... .......... .......... .......... ..........  0% 12.7M 13h38m\n",
      "   200K .......... .......... .......... .......... ..........  0%  282K 14h23m\n",
      "   250K .......... .......... .......... .......... ..........  0% 9.89M 12h4m\n",
      "   300K .......... .......... .......... .......... ..........  0% 12.2M 10h23m\n",
      "   350K .......... .......... .......... .......... ..........  0% 10.7M 9h9m\n",
      "   400K .......... .......... .......... .......... ..........  0%  297K 9h58m\n",
      "   450K .......... .......... .......... .......... ..........  0% 12.0M 9h0m\n",
      "   500K .......... .......... .......... .......... ..........  0% 11.9M 8h13m\n",
      "   550K .......... .......... .......... .......... ..........  0% 10.1M 7h35m\n",
      "   600K .......... .......... .......... .......... ..........  0% 11.7M 7h1m\n",
      "   650K .......... .......... .......... .......... ..........  0% 11.1M 6h33m\n",
      "   700K .......... .......... .......... .......... ..........  0% 10.7M 6h9m\n",
      "   750K .......... .......... .......... .......... ..........  0% 12.0M 5h47m\n",
      "   800K .......... .......... .......... .......... ..........  0% 7.18M 5h29m\n",
      "   850K .......... .......... .......... .......... ..........  0%  342K 5h58m\n",
      "   900K .......... .......... .......... .......... ..........  0% 11.9M 5h41m\n",
      "   950K .......... .......... .......... .......... ..........  0% 12.3M 5h25m\n",
      "  1000K .......... .......... .......... .......... ..........  0% 9.69M 5h11m\n",
      "  1050K .......... .......... .......... .......... ..........  0% 12.3M 4h58m\n",
      "  1100K .......... .......... .......... .......... ..........  0% 11.9M 4h46m\n",
      "  1150K .......... .......... .......... .......... ..........  0% 9.92M 4h35m\n",
      "  1200K .......... .......... .......... .......... ..........  0% 9.72M 4h25m\n",
      "  1250K .......... .......... .......... .......... ..........  0% 10.1M 4h16m\n",
      "  1300K .......... .......... .......... .......... ..........  0% 11.7M 4h8m\n",
      "  1350K .......... .......... .......... .......... ..........  0% 10.1M 4h0m\n",
      "  1400K .......... .......... .......... .......... ..........  0% 11.8M 3h52m\n",
      "  1450K .......... .......... .......... .......... ..........  0% 12.0M 3h45m\n",
      "  1500K .......... .......... .......... .......... ..........  0% 85.3K 5h29m\n",
      "  1550K .......... .......... .......... .......... ..........  0% 19.5K 13h10m\n",
      "  1600K .......... .......... .......... .......... ........"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# wget http://bioinformatics.nl/~kauts001/ltr/bigslice/paper_data/data/full_run_result.zip --directory-prefix  ${WORKDIR}/data/\n",
    "# unzip ${WORKDIR}/data/full_run_result.zip"
   ]
  },
  {
   "cell_type": "raw",
   "id": "671e865c-7374-478d-a859-dcfdfa0626e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "And now run [BiG-SLICE](https://github.com/medema-group/bigslice) using our containerized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e8beb17-2584-40ed-8da1-adc06969b6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to find image 'epereira/bigslice:latest' locally\n",
      "docker: Error response from daemon: pull access denied for epereira/bigslice, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.\n",
      "See 'docker run --help'.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\"${REPO}\"/run_scripts/run_bigslice.sh query \\\\\\n\"${WORKDIR}/outputs/antismash/\" \\\\\\n\"${WORKDIR}/data/full_run_result\"\\n'' returned non-zero exit status 125.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_cell_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbash\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{REPO}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/run_scripts/run_bigslice.sh query \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{WORKDIR}\u001b[39;00m\u001b[38;5;124m/outputs/antismash/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;132;01m{WORKDIR}\u001b[39;00m\u001b[38;5;124m/data/full_run_result\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2475\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2473\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2474\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2475\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2477\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:153\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshebang(line, cell)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/magics/script.py:305\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\"${REPO}\"/run_scripts/run_bigslice.sh query \\\\\\n\"${WORKDIR}/outputs/antismash/\" \\\\\\n\"${WORKDIR}/data/full_run_result\"\\n'' returned non-zero exit status 125."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\"${REPO}\"/run_scripts/run_bigslice.sh query \\\n",
    "\"${WORKDIR}/outputs/antismash/\" \\\n",
    "\"${WORKDIR}/data/full_run_result\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
