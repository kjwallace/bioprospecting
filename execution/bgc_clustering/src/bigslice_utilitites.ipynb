{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "534aa71b-cf09-4084-8a3d-5f15ff3abd58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def create_dataset_table(path_to_input_folder : str = None):\n",
    "  \n",
    "    '''\n",
    "    path_to_data:\n",
    "        type: str \n",
    "        Contains the relative path from the notebook to the input folder \n",
    "        conatining the metagenomic datasets and assemblies subfolders, the \n",
    "        latter with annotated BGC sequences to be clustered.\n",
    "    returns:\n",
    "        A tsv file located in the root directory of the input folder, having the columns: \n",
    "        1. Dataset name.\n",
    "        2. Path to dataset folder (relative to input folder's root folder).\n",
    "        3. Path to taxonomy file (see <taxonomy_X.tsv> files).\n",
    "        4. Description of the dataset.\n",
    "    '''\n",
    "    \n",
    "    if path_to_input_folder == None:\n",
    "        print('You need to insert a path to the input folder')\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(path_to_input_folder):\n",
    "        print('You need to insert a valid path to the input folder')\n",
    "        return False\n",
    "      \n",
    "    '''\n",
    "    Get the data to populate each column of the output table.\n",
    "    Each line of the output table will be sotred in as list. \n",
    "    All these list will be stored in higher level list. \n",
    "    '''\n",
    "    \n",
    "    subfolders = os.listdir(path_to_input_folder)  \n",
    "    path_to_input_folder_list = path_to_input_folder.split('/')\n",
    "    path_to_dataset = path_to_input_folder_list[3]\n",
    "    output_list = list()\n",
    "\n",
    "    for dataset in subfolders:\n",
    "        if dataset != \"datasets.tsv\" and dataset != \"taxonomy\":\n",
    "            dataset_line = [dataset, \"./\", f\"taxonomy/{dataset}_taxonomy.tsv\",f\"dataset_{dataset}\"]\n",
    "            output_list.append(dataset_line)\n",
    "\n",
    "    '''\n",
    "    Define the output file name \n",
    "    '''\n",
    "    \n",
    "    output_tsv = f'{path_to_input_folder}/datasets.tsv'\n",
    "    \n",
    "    '''\n",
    "    Write outout tsv file\n",
    "    ''' \n",
    "    \n",
    "    try:\n",
    "        with open(output_tsv, 'w', newline='') as tsv_file:\n",
    "            tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "            for row in output_list:\n",
    "                 tsv_writer.writerow(row)  \n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e}\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbe633-80b9-4c24-b7c4-fbedfea527dc",
   "metadata": {},
   "source": [
    "### Description of create_dataset_table function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ceebe-5f49-4495-bcc2-e1d2e228e517",
   "metadata": {},
   "source": [
    "This function reads the names of the subfolders in the input directory (i.e., metagenomic datasets), to create the datasets.tsv tables needed to run [BiG-SLICE](https://github.com/pereiramemo/bigslice) as described [here](https://github.com/medema-group/bigslice/wiki/Input-folder#datasetstsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "881b161e-a9b1-496c-b1ba-1f34070f8e52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def find_files(folder_path : str = None) -> list:\n",
    "  \n",
    "    '''\n",
    "    folder_path:\n",
    "        type: str \n",
    "        Contains the relative path from the notebook to the input folder \n",
    "    returns:\n",
    "        A list with all the files having named with the format *reion\\d+.gbk    \n",
    "        '''\n",
    "  \n",
    "    pattern = r\".*\\.region\\d+.gbk\"\n",
    "    matching_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if re.search(pattern, file):\n",
    "                matching_files.append(os.path.join(root, file))\n",
    "    return matching_files\n",
    "  \n",
    "def create_taxonomy_tables(path_to_input_folder : str = None):\n",
    "  \n",
    "    '''\n",
    "    path_to_data:\n",
    "        type: str \n",
    "        Contains the relative path from the notebook to the input folder \n",
    "        conatining the metagenomic datasets and assemblies subfolders, the \n",
    "        latter with annotated BGC sequences to be clustered.\n",
    "    returns:\n",
    "        A tsv file per sample located in a taxonomy directory created in the \n",
    "        root directory of the input folder, having the columns: \n",
    "        1. Sequence identification.\n",
    "        2. Taxonomy.\n",
    "    '''\n",
    "    \n",
    "    if path_to_input_folder == None:\n",
    "        print('You need to insert a path to the input folder')\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(path_to_input_folder):\n",
    "        print('You need to insert a valid path to the input folder')\n",
    "        return False\n",
    "    \n",
    "    '''\n",
    "    Create output directory.\n",
    "    '''\n",
    "    \n",
    "    taxomoy_dir = f\"{path_to_input_folder}/taxonomy\"\n",
    "    if not os.path.exists(taxomoy_dir):\n",
    "       os.makedirs(taxomoy_dir)\n",
    "    \n",
    "    '''\n",
    "    Crete a dictionary of lists of lists containing the data do crate the taxonomy files. \n",
    "    Each element in the dictionary will be used to create a tsv file.\n",
    "    '''\n",
    "    \n",
    "    output_dict = dict()  \n",
    "    subfolders = os.listdir(path_to_input_folder)\n",
    "    for subfolder in subfolders:\n",
    "        if subfolder != \"datasets.tsv\" and subfolder != \"taxonomy\": \n",
    "            output_dict[subfolder] = list()\n",
    "            path_to_input_subfolder = \"/\".join([path_to_input_folder, subfolder])\n",
    "            path_to_gbk_files_list = find_files(path_to_input_subfolder)\n",
    "            gbk_files = [x.split(\"/\")[-1] for x in path_to_gbk_files_list]\n",
    "            for gbk_file in gbk_files:\n",
    "                gbk_file = gbk_file.replace(\".gbk\", '')\n",
    "                output_dict[subfolder].append([gbk_file, \"NA\"])\n",
    "    \n",
    "    for key in output_dict:\n",
    "        '''\n",
    "        Define file name.\n",
    "        '''\n",
    "        output_list = output_dict[key]\n",
    "        output_tsv = f'{taxomoy_dir}/{key}_taxonomy.tsv'\n",
    "        '''\n",
    "        Write outout tsv file\n",
    "        ''' \n",
    "        try:\n",
    "            with open(output_tsv, 'w', newline='') as tsv_file:\n",
    "                tsv_writer = csv.writer(tsv_file, delimiter='\\t')\n",
    "                for row in output_list:\n",
    "                     tsv_writer.writerow(row)  \n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea92da-4654-477d-8c29-5aa02e35d0a8",
   "metadata": {},
   "source": [
    "### Description of create_dataset_table function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f4fb6-f274-4aea-9c1a-783aab82f2b4",
   "metadata": {},
   "source": [
    "This function reads the names of the subfolders in the input directory (i.e., metagenomic datasets), and the GenBank files named with the format \"\\*.region\\d+.gbk\" as generated by [antiSMASH](https://github.com/antismash/antismash) in order the create the taxonomy files required to run [BiG-SLICE](https://github.com/pereiramemo/bigslice) as described [here](https://github.com/medema-group/bigslice/wiki/Input-folder#datasetstsv). At the moment, the function only generates the files without any taxonomic information, since the taxonomy is analyzed independently of BiG-SLICE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
