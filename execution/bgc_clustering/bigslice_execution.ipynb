{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f89cfa5-4c2f-4b5c-839f-2d22252fb17d",
   "metadata": {},
   "source": [
    "![image](https://cdn.discordapp.com/attachments/996200880351215636/1065002848355631165/New_Atlantis.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d56b0-ecb4-47e9-b471-8fcee9da8a87",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Execution of the BiG-SLICE Tool: clustering mode\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5e14e4-f345-41da-8ab4-29d41771ae56",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41f9a9-6c2d-47a9-a063-5e9c5b07e0a5",
   "metadata": {},
   "source": [
    "[BiG-SLICE](https://github.com/pereiramemo/bigslice) is a tool designed to cluster BGC sequences into Gene Cluster Families (GCFs) based on their protein domain composition utilizing the [Balanced Iterative Reducing and Clustering using Hierarchies (BIRCH)](https://en.wikipedia.org/wiki/BIRCH) algorithm (which is a near-linear time complexity clustering algorithm).\n",
    "The tool can be executed in clustering mode or query mode, which perform the de novo clustering of BGC sequences and the positioning of query BGC sequences onto previously computed GCF models, respectively.   \n",
    "This notebook is dedicated to the excution of the BiG-SLICE tool utlizing the clustering mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa602b-c578-40ab-a325-c25734c912aa",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800a33bf-bdf4-412a-9b7f-58a4dea69722",
   "metadata": {},
   "source": [
    "### 1.1 Create directories (run then comment)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861ea586-f45c-4e37-a828-3eb8be7f5df8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os \n",
    "\n",
    "# if not os.path.exists('./src'):\n",
    "#     os.makedirs('./src')\n",
    "#     os.makedirs('./data')\n",
    "#     os.makedirs('./data/input_data')\n",
    "#     os.makedirs('./data/output_data')\n",
    "#     os.makedirs('./data/reference_data')\n",
    "#     with open('./src/requirements.txt', 'w') as f:\n",
    "#         pass\n",
    "#     with open('./src/utilities.ipynb', 'a') as nb:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c9dea-7126-4093-8fb3-ef15b5a6494a",
   "metadata": {},
   "source": [
    "### 1.2 Input data \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e028d77b-b270-4032-949f-2d2bd47125e6",
   "metadata": {},
   "source": [
    "Input data consits of BGC sequences (complete or partial) annotated in contigs of Metagenome Assembled Genomes (MAGs), sotred as GenBank files and named fwollowing the [antiSMASH](https://github.com/antismash/antismash) or [MIBiG](https://mibig.secondarymetabolites.org/) nomenclature (i.e., <genome_name>.regionXXX.gbk and BGCXXXXXXX.gbk, respectively). \n",
    "These sequences have to be organized in a directory structure having the dataset and genomes subfolders as specified [here](https://github.com/medema-group/bigslice/wiki/Input-folder).\n",
    "This is the input data that the user must provide to run this Notebook. However, in order to being able execute the BiG-SLICE tool, here we are automatically generating the dataset.tsv and taxonomy.tsv files as described [here](https://github.com/medema-group/bigslice/wiki/Input-folder#datasetstsv).  \n",
    "For demonstration purposes, here we will be analyzing 38 metagenomics samples of the [SOLA dataset](https://pubmed.ncbi.nlm.nih.gov/29925880/), which is a time series dataset spanning three years (from 2012 to 2015) obtained from a coastal northwestern Mediterranean site."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2803ae5-51dc-4a2d-b442-170a8f18412d",
   "metadata": {},
   "source": [
    "### 1.3 Output data \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85d43d-7a3c-4b46-8059-6293d0ec700a",
   "metadata": {},
   "source": [
    "A SQLite database is created with the following schema: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6c1ce-c2b1-4aae-9245-efb389c8d93a",
   "metadata": {},
   "source": [
    "```\n",
    "CREATE TABLE bgc (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    dataset_id INTEGER NOT NULL,\n",
    "    name VARCHAR(250) NOT NULL,\n",
    "    type VARCHAR(10) NOT NULL,\n",
    "    on_contig_edge BOOLEAN,\n",
    "    length_nt INTEGER NOT NULL,\n",
    "    orig_folder VARCHAR(1500) NOT NULL,\n",
    "    orig_filename VARCHAR(1500) NOT NULL,\n",
    "    UNIQUE(orig_folder, orig_filename, dataset_id),\n",
    "    FOREIGN KEY(dataset_id) REFERENCES dataset(id),\n",
    "    FOREIGN KEY(type) REFERENCES enum_bgc_type(code)\n",
    ");\n",
    "CREATE TABLE sqlite_sequence(name,seq);\n",
    "CREATE TABLE bgc_class (\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    chem_subclass_id INTEGER NOT NULL,\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id),\n",
    "    FOREIGN KEY(chem_subclass_id) REFERENCES chem_subclass(id)\n",
    ");\n",
    "CREATE TABLE bgc_features (\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    hmm_id INTEGER NOT NULL,\n",
    "    value INTEGER NOT NULL,\n",
    "    UNIQUE(bgc_id, hmm_id),\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id),\n",
    "    FOREIGN KEY(hmm_id) REFERENCES hmm(id)\n",
    ");\n",
    "CREATE TABLE bgc_taxonomy (\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    taxon_id INTEGER NOT NULL,\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id),\n",
    "    FOREIGN KEY(taxon_id) REFERENCES taxon(id)\n",
    ");\n",
    "CREATE TABLE cds (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    nt_start INTEGER NOT NULL,\n",
    "    nt_end INTEGER NOT NULL,\n",
    "    strand INTEGER CHECK(strand IN (-1,0,1)),\n",
    "    locus_tag VARCHAR(100),\n",
    "    protein_id VARCHAR(100),\n",
    "    product VARCHAR(100),\n",
    "    aa_seq TEXT NOT NULL,\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id)\n",
    ");\n",
    "CREATE TABLE chem_class (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name VARCHAR(100) NOT NULL UNIQUE\n",
    ");\n",
    "CREATE TABLE chem_subclass (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    class_id INTEGER NOT NULL,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    FOREIGN KEY(class_id) REFERENCES chem_class(id)\n",
    ");\n",
    "CREATE TABLE chem_subclass_map (\n",
    "    class_source VARCHAR(100) NOT NULL,\n",
    "    type_source VARCHAR(10) NOT NULL,    \n",
    "    subclass_id INTEGER NOT NULL,\n",
    "    FOREIGN KEY(type_source) REFERENCES enum_bgc_type(code),\n",
    "    FOREIGN KEY(subclass_id) REFERENCES chem_subclass(id)\n",
    ");\n",
    "CREATE TABLE clustering (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    run_id INTEGER NOT NULL UNIQUE,\n",
    "    clustering_method VARCHAR(100) NOT NULL,\n",
    "    num_centroids INTEGER NOT NULL,\n",
    "    threshold REAL NOT NULL,\n",
    "    random_seed INTEGER NOT NULL,\n",
    "    FOREIGN KEY(run_id) REFERENCES run(id)\n",
    ");\n",
    "CREATE TABLE dataset (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name VARCHAR(250) NOT NULL UNIQUE,\n",
    "    orig_folder VARCHAR(250) NOT NULL,\n",
    "    description VARCHAR(2500) NOT NULL\n",
    ");\n",
    "CREATE TABLE enum_bgc_type (\n",
    "    code VARCHAR(10) PRIMARY KEY,\n",
    "    description VARCHAR(250)\n",
    ");\n",
    "CREATE TABLE enum_run_status (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name VARCHAR(100) NOT NULL UNIQUE\n",
    ");\n",
    "CREATE TABLE gcf (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    id_in_run INTEGER NOT NULL,\n",
    "    clustering_id INTEGER NOT NULL,\n",
    "    UNIQUE(id_in_run, clustering_id),\n",
    "    FOREIGN KEY(clustering_id) REFERENCES clustering(id)\n",
    ");\n",
    "CREATE TABLE gcf_membership (\n",
    "    gcf_id INTEGER NOT NULL,\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    membership_value REAL NOT NULL,\n",
    "    rank INTEGER NOT NULL,\n",
    "    FOREIGN KEY(gcf_id) REFERENCES gcf(id),\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id)\n",
    ");\n",
    "CREATE TABLE gcf_models (\n",
    "    gcf_id INTEGER NOT NULL,\n",
    "    hmm_id INTEGER NOT NULL,\n",
    "    value REAL NOT NULL,\n",
    "    UNIQUE(gcf_id, hmm_id),\n",
    "    FOREIGN KEY(gcf_id) REFERENCES gcf(id),\n",
    "    FOREIGN KEY(hmm_id) REFERENCES hmm(id)\n",
    ");\n",
    "CREATE TABLE hmm (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    accession VARCHAR(10),\n",
    "    name VARCHAR(25) NOT NULL,\n",
    "    db_id INTEGER NOT NULL,\n",
    "    model_length INTEGER NOT NULL,\n",
    "    FOREIGN KEY(db_id) REFERENCES hmm_db(id)\n",
    ");\n",
    "CREATE TABLE hmm_db (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    md5_biosyn_pfam CHAR(32) NOT NULL,\n",
    "    md5_sub_pfam CHAR(32) NOT NULL\n",
    ");\n",
    "CREATE TABLE hsp (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    cds_id INTEGER NOT NULL,\n",
    "    hmm_id INTEGER NOT NULL,\n",
    "    bitscore REAL NOT NULL,\n",
    "    FOREIGN KEY(cds_id) REFERENCES cds(id),\n",
    "    FOREIGN KEY(hmm_id) REFERENCES hmm(id)    \n",
    ");\n",
    "CREATE TABLE hsp_alignment (\n",
    "    hsp_id INTEGER UNIQUE NOT NULL,\n",
    "    model_start INTEGER NOT NULL,\n",
    "    model_end INTEGER NOT NULL,\n",
    "    model_gaps TEXT NOT NULL,\n",
    "    cds_start INTEGER NOT NULL,\n",
    "    cds_end INTEGER NOT NULL,\n",
    "    cds_gaps TEXT NOT NULL,\n",
    "    FOREIGN KEY(hsp_id) REFERENCES hsp(id)\n",
    ");\n",
    "CREATE TABLE hsp_subpfam (\n",
    "    hsp_subpfam_id INTEGER NOT NULL,\n",
    "    hsp_parent_id INTEGER NOT NULL,\n",
    "    UNIQUE(hsp_subpfam_id, hsp_parent_id),\n",
    "    FOREIGN KEY(hsp_subpfam_id) REFERENCES hsp(id),\n",
    "    FOREIGN KEY(hsp_parent_id) REFERENCES hsp(id)\n",
    ");\n",
    "CREATE TABLE run (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    status INTEGER NOT NULL,\n",
    "    prog_params VARCHAR(250) NOT NULL,\n",
    "    hmm_db_id INTEGER,\n",
    "    FOREIGN KEY(status) REFERENCES enum_run_status(id),\n",
    "    FOREIGN KEY(hmm_db_id) REFERENCES hmm_db(id)\n",
    ");\n",
    "CREATE TABLE run_bgc_status (\n",
    "    bgc_id INTEGER NOT NULL,\n",
    "    run_id INTEGER NOT NULL,\n",
    "    status INTEGER NOT NULL,\n",
    "    FOREIGN KEY(bgc_id) REFERENCES bgc(id),\n",
    "    FOREIGN KEY(run_id) REFERENCES run(id),\n",
    "    FOREIGN KEY(status) REFERENCES enum_run_status(id)\n",
    ");\n",
    "CREATE TABLE run_log (\n",
    "    run_id INTEGER NOT NULL,\n",
    "    time_stamp DATETIME NOT NULL,\n",
    "    message VARCHAR(500) NOT NULL\n",
    ");\n",
    "CREATE TABLE schema (\n",
    "    ver VARCHAR(10) PRIMARY KEY\n",
    ");\n",
    "CREATE TABLE subpfam (\n",
    "    hmm_id INTEGER NOT NULL,\n",
    "    parent_hmm_id INTEGER NOT NULL,\n",
    "    FOREIGN KEY(hmm_id) REFERENCES hmm(id),\n",
    "    FOREIGN KEY(parent_hmm_id) REFERENCES hmm(id)\n",
    ");\n",
    "CREATE TABLE taxon (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    level INTEGER NOT NULL,\n",
    "    name VARCHAR(100) NOT NULL,\n",
    "    UNIQUE(name, level),\n",
    "    FOREIGN KEY(level) REFERENCES taxon_class(level)\n",
    ");\n",
    "CREATE TABLE taxon_class (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    level INTEGER NOT NULL UNIQUE,\n",
    "    name VARCHAR(100) NOT NULL UNIQUE\n",
    ");\n",
    "CREATE INDEX dataset_name ON dataset(name);\n",
    "CREATE INDEX bgc_dataset ON bgc(dataset_id);\n",
    "CREATE INDEX bgc_name ON bgc(name);\n",
    "CREATE INDEX bgc_type ON bgc(type);\n",
    "CREATE INDEX bgc_gbkpath ON bgc(orig_folder, orig_filename);\n",
    "CREATE INDEX bgc_filename ON bgc(orig_filename);\n",
    "CREATE INDEX bgc_contigedge ON bgc(on_contig_edge);\n",
    "CREATE INDEX bgc_length ON bgc(length_nt);\n",
    "CREATE INDEX cds_bgc ON cds(bgc_id,nt_start,nt_end);\n",
    "CREATE INDEX hmm_acc ON hmm(db_id, accession);\n",
    "CREATE INDEX hmm_name ON hmm(db_id, name);\n",
    "CREATE INDEX subpfam_parenthmm ON subpfam(parent_hmm_id, hmm_id);\n",
    "CREATE INDEX hsp_cdshmm ON hsp(cds_id, hmm_id);\n",
    "CREATE INDEX hsp_bitscore ON hsp(bitscore);\n",
    "CREATE INDEX hspalign_id ON hsp_alignment(hsp_id);\n",
    "CREATE INDEX hspalign_model ON hsp_alignment(model_start);\n",
    "CREATE INDEX hspalign_cds ON hsp_alignment(cds_start);\n",
    "CREATE INDEX hspsubpfam_parent ON hsp_subpfam(hsp_parent_id, hsp_subpfam_id);\n",
    "CREATE INDEX hspsubpfam_sub ON hsp_subpfam(hsp_subpfam_id, hsp_parent_id);\n",
    "CREATE UNIQUE INDEX taxon_class_level ON taxon_class(level);\n",
    "CREATE UNIQUE INDEX taxon_class_name ON taxon_class(name);\n",
    "CREATE INDEX taxon_level ON taxon(level, name);\n",
    "CREATE INDEX taxon_name ON taxon(name, level);\n",
    "CREATE INDEX bgctaxonomy_bgcid ON bgc_taxonomy(bgc_id);\n",
    "CREATE INDEX bgctaxonomy_taxid ON bgc_taxonomy(taxon_id);\n",
    "CREATE UNIQUE INDEX chemclass_name ON chem_class(name);\n",
    "CREATE INDEX chemsubclass_name ON chem_subclass(name, class_id);\n",
    "CREATE INDEX chemsubclass_class ON chem_subclass(class_id, name);\n",
    "CREATE INDEX chemsubclassmap_source ON chem_subclass_map(type_source, class_source);\n",
    "CREATE INDEX bgcclass_chemsubclass ON bgc_class(chem_subclass_id, bgc_id);\n",
    "CREATE INDEX bgcclass_bgc ON bgc_class(bgc_id, chem_subclass_id);\n",
    "CREATE UNIQUE INDEX enumrunstatus_name ON enum_run_status(name);\n",
    "CREATE INDEX run_hmmdb ON run(hmm_db_id, status);\n",
    "CREATE INDEX runlog_run ON run_log(run_id, time_stamp);\n",
    "CREATE INDEX runbgcstatus_run_status ON run_bgc_status(run_id, status, bgc_id);\n",
    "CREATE INDEX runbgcstatus_run_bgc ON run_bgc_status(run_id, bgc_id, status);\n",
    "CREATE INDEX bgc_features_bgc ON bgc_features(bgc_id, hmm_id, value);\n",
    "CREATE INDEX bgc_features_bgc_value ON bgc_features(value, bgc_id, hmm_id);\n",
    "CREATE INDEX bgc_features_hmm ON bgc_features(hmm_id, bgc_id, value);\n",
    "CREATE INDEX bgc_features_hmm_value ON bgc_features(value, hmm_id, bgc_id);\n",
    "CREATE INDEX clustering_run ON clustering(run_id);\n",
    "CREATE INDEX gcf_clustering ON gcf(clustering_id, id_in_run);\n",
    "CREATE INDEX gcf_models_gcf ON gcf_models(gcf_id, hmm_id, value);\n",
    "CREATE INDEX gcf_models_gcf_value ON gcf_models(value, gcf_id, hmm_id);\n",
    "CREATE INDEX gcf_models_hmm ON gcf_models(hmm_id, gcf_id);\n",
    "CREATE INDEX gcf_models_hmm_value ON gcf_models(value, hmm_id, gcf_id);\n",
    "CREATE INDEX gcf_membership_gcf_rank ON gcf_membership(gcf_id, rank);\n",
    "CREATE INDEX gcf_membership_gcf_val ON gcf_membership(gcf_id, membership_value);\n",
    "CREATE INDEX gcf_membership_bgc_rank ON gcf_membership(bgc_id, rank);\n",
    "CREATE INDEX gcf_membership_bgc_val ON gcf_membership(bgc_id, membership_value);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30735204-59a5-4304-8891-ae498e3dbc00",
   "metadata": {},
   "source": [
    "### 1.4 Data loading\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e728dc9f-1b4a-422a-83ca-54d23bf1af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp -r ../bgc_annotation/data/output_data/sola_antismashed ./data/input_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90a79e-33d2-4b4e-bbfe-9987c18b25f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 2. Environment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb8ad4-f3f8-4bd1-a284-f4dc25b8f6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Main dependencies\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4ff5f6-8795-431d-84d8-6c9a1e46036b",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Docker](https://www.docker.com/)  \n",
    "[tidyverse R package](https://www.tidyverse.org/)  \n",
    "[RSQLite R package](https://cran.r-project.org/web/packages/RSQLite/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59918e52-950c-48a9-a885-ea9ff54cf05f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Notebook utility installs\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a90163-e6f7-49a3-a2d5-3d5d804b0933",
   "metadata": {},
   "source": [
    "The import-ipynb package installed here provides utility in using a refernce notebook as a Python module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a6b44b-8afd-4c80-b11d-0a0bcd78a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install for import-ipynb that will be applied later\n",
    "!pip3 install import-ipynb -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997df0a0-0b9b-444b-a6bb-f8905e4e2c98",
   "metadata": {},
   "source": [
    "### 2.3 R Based dependencies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647a4a2-f0e6-4960-bcd2-9d29cd97a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!Rscript -e 'install.packages(\"tidyverse\")' &> /dev/null\n",
    "!Rscript -e 'install.packages(\"RSQLite\")' &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cc56d-36e9-482d-93cc-636158a2d3f5",
   "metadata": {},
   "source": [
    "### 2.4 Import statements (code)(import ipynb)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7b3ebf-21a7-46c4-8701-b3a02a69ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from /home/epereira/workspace/dev/new_atlantis/repos/bioprospecting/execution/bgc_clustering/src/utilitites.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from src.utilitites import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee330ce-46eb-4634-bb17-b06ab1fc09c1",
   "metadata": {},
   "source": [
    "### 2.5 Session envrionmental variables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af655571-741c-4cdd-abec-51f1ea104a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ddae72-6500-4f99-9a8c-27206ab52da1",
   "metadata": {},
   "source": [
    "### 2.6 Input and output data files and directories \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad658ff-23c4-4335-a90d-628a13495549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: INPUT_DIR=./data/input_data/sola_antismashed\n"
     ]
    }
   ],
   "source": [
    "%env INPUT_DIR=./data/input_data/sola_antismashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995b8e75-c113-453b-b8a7-49eb3f115ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OUTPUT_DIR=./data/output_data/sola_bigsiced\n"
     ]
    }
   ],
   "source": [
    "%env OUTPUT_DIR=./data/output_data/sola_bigsiced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51905b-74dd-42d9-9b66-5e1e8f56cb60",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 3. Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0479a5-6f3b-42e5-a7b7-87327f743d0f",
   "metadata": {},
   "source": [
    "`-t <N>, --num_threads <N>` The number of parallel jobs to run (default: 48)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9399b0-477f-4128-bd7d-a772586b481e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%env NUM_THREADS=40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6f220-6fb4-43f7-89d3-76c8f8499fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "`-threshold_pct <N>` Calculate clustering threshold (T) based on a random sampling of pairwise distances between the data, taking the N-th percentile value as the threshold.  \n",
    "Mutually exclusive with --threshold, use '-1' to turn off this parameter (default: -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689130ba-7ea3-46bd-a8c4-9e5102cdf109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THRESHOLD_PCT=0.1\n"
     ]
    }
   ],
   "source": [
    "%env THRESHOLD_PCT=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96260cdb-cfc4-4b17-b686-6aba52f13c64",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 4. Data Precleaning (if required) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9fc63-3946-455c-9a3a-230567324206",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once we have annotated the BGC sequences in our aseembled metagenomic samples utilizing the bgc_annotation notebook, we have the following folders strucutre:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d900e193-b0d5-4f5b-849f-dcc028ce0004",
   "metadata": {},
   "source": [
    "> * input_folder/\n",
    ">   * metagenomic_dataset_1/\n",
    ">     * assembly/\n",
    ">       * contig_1.region001.gbk\n",
    ">       * contig_2.region002.gbk\n",
    ">       * ...\n",
    ">   * metagenomic_dataset_2/\n",
    ">     * assembly/\n",
    ">       * contig_1.region001.gbk\n",
    ">       * contig_2.region002.gbk\n",
    ">       * ...  \n",
    ">   * ...        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45d08f-543f-4c76-aba3-bb6e22ce7055",
   "metadata": {},
   "source": [
    "Let's check how our example dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00519864-5634-420c-8277-9e8468d3d9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/input_data/sola_antismashed/ERR2604071:\n",
      "scaffolds\n",
      "\n",
      "./data/input_data/sola_antismashed/ERR2604073:\n",
      "scaffolds\n",
      "\n",
      "./data/input_data/sola_antismashed/ERR2604074:\n",
      "scaffolds\n",
      "\n",
      "./data/input_data/sola_antismashed/ERR2604075:\n",
      "scaffolds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!ls \"${INPUT_DIR}\"/* | head -12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8f9d5-dec2-40e9-9aa9-821a26ff9d6c",
   "metadata": {},
   "source": [
    "When running the following command we should see all the identified BGC sequences in GenBank format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfc46c6d-e045-4a0d-8372-4674b87fbb21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_156069.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_116291.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_33754.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_73676.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_146697.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_9801.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_111249.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_102369.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_8575.region001.gbk\n",
      "./data/input_data/sola_antismashed/ERR2604088/scaffolds/ERR2604088__k119_63734.region001.gbk\n",
      "find: ‘standard output’: Broken pipe\n",
      "find: write error\n"
     ]
    }
   ],
   "source": [
    "!find \"${INPUT_DIR}\" -mindepth 3 -maxdepth 3 -type f -name \"*region*.gbk\" | head "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35853b2c-c25d-49ba-a843-fc7a1472f7fb",
   "metadata": {},
   "source": [
    "Now that we checked that we have the GenBank files and the directory has the proper structure we are going to generate the `datasets.tsv` and `taxonomy.tsv` files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bee7363d-231e-4e46-81b6-3ff7611837f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_dataset_table(\"./data/input_data/sola_antismashed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77aa33-4d84-4ffe-95db-7b912ed40cda",
   "metadata": {},
   "source": [
    "Next we have to create the taxonomy files. These files are only created to comply with files required to run BiG-SLICE, the taxonomic information is analyzed in a different notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea001275-54f7-4f08-b340-77688ab68612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_taxonomy_tables(\"./data/input_data/sola_antismashed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f64e2f-e7ea-472d-9942-2010e2dcb193",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# 5. Execution of Tool \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb48725-d14d-4d5c-819e-28cd0583c13b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!\"src/run_bigslice.sh\" cluster \"${INPUT_DIR}\" \"${OUTPUT_DIR}\" \\\n",
    "--num_threads \"${NUM_THREADS}\" \\\n",
    "--threshold_pct \"${THRESHOLD_PCT}\" &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa663f-fc33-4af2-b25b-195edeeb5f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Data Post Processing (if required) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d262b3-64e7-47ec-bb18-41d1691612aa",
   "metadata": {},
   "source": [
    "## Write to output directory\n",
    "---\n",
    "If the tool does not do it automatically, use this cell to write the output data to the output directory defined in the parameter section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f5b0f-10dc-429d-82a0-e5ce3b55a7a5",
   "metadata": {},
   "source": [
    "This section aims to contain all the code necessary to perform the data cleaning, formatting or analysis that would be performed on the output of this tool. Use the same formatting as previously mentioned in the execution section of the notebook:\n",
    "- Offload long code sections to the src/Utility_NB and import the code \n",
    "- Add validation to catch errors in and irregularities in the data \n",
    "- Alternate code and markdown cells \n",
    "- Include a markdown header for each step using ### to add it to the table of contents\n",
    "- Display data and transformations where necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a420e-919a-47ba-a8b5-15e2a0733e54",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion\n",
    "---\n",
    "Include any final parting thoughts in this section.\n",
    "This section may also incude:\n",
    "- Common mistakes and fixes. \n",
    "- Debugging tips.\n",
    "- Contact for the author.\n",
    "- Any other information you would like to include"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56339f87-34a1-4fad-a584-9ebfa2be866b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9825cda-38b4-4a11-9a35-315f96dfa27f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc821a5-1d24-4899-ae87-24aa86d05c60",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c532b35d-5cc4-48b9-a09f-2f09ebe08d27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8001bd4-2ad7-4c32-8117-cd5d5a050bd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "505e23f4-f056-4803-b336-973de2b5a061",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
